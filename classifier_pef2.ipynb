{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671c5179-7e39-406e-a198-fcdc2747e42e",
   "metadata": {
    "id": "671c5179-7e39-406e-a198-fcdc2747e42e"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f484e-9b8d-4a3d-8fc7-a5ced0b67a37",
   "metadata": {
    "id": "d83f484e-9b8d-4a3d-8fc7-a5ced0b67a37"
   },
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "training_data = np.load(\"C:\\\\Users\\\\andre\\\\OneDrive\\\\Escritorio\\\\PEF II\\\\Projecte PEF\\\\Mock_train_FLUX+NOISE.npy\")\n",
    "training_properties = Table.read(\"C:\\\\Users\\\\andre\\\\OneDrive\\\\Escritorio\\\\PEF II\\\\Projecte PEF\\\\Mock_train_PROPS.csv\")\n",
    "validation_data = np.load(\"C:\\\\Users\\\\andre\\\\OneDrive\\\\Escritorio\\\\PEF II\\\\Projecte PEF\\\\Mock_valid_FLUX+NOISE.npy\")\n",
    "validation_properties = Table.read(\"C:\\\\Users\\\\andre\\\\OneDrive\\\\Escritorio\\\\PEF II\\\\Projecte PEF\\\\Mock_valid_PROPS.csv\")\n",
    "test_data = np.load(\"C:\\\\Users\\\\andre\\\\OneDrive\\\\Escritorio\\\\PEF II\\\\Projecte PEF\\\\Mock_test_FLUX+NOISE.npy\")\n",
    "test_properties = Table.read(\"C:\\\\Users\\\\andre\\\\OneDrive\\\\Escritorio\\\\PEF II\\\\Projecte PEF\\\\Mock_test_PROPS.csv\")\n",
    "real_data = np.load(\"C:\\\\Users\\\\andre\\\\OneDrive\\\\Escritorio\\\\PEF II\\\\Projecte PEF\\\\JPAS_DATA_Aper_Cor_3_FLUX+NOISE.npy\")\n",
    "real_properties = Table.read(\"C:\\\\Users\\\\andre\\\\OneDrive\\\\Escritorio\\\\PEF II\\\\Projecte PEF\\\\JPAS_DATA_PROPERTIES.csv\")\n",
    "\n",
    "## Convert Table Astropy to a pandas DF\n",
    "training_properties_df = training_properties.to_pandas() \n",
    "validation_properties_df = validation_properties.to_pandas() \n",
    "test_properties_df = test_properties.to_pandas()\n",
    "real_properties_df = real_properties.to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edfc63e-0bd2-4a63-9bdb-70baaad09bce",
   "metadata": {
    "id": "9edfc63e-0bd2-4a63-9bdb-70baaad09bce"
   },
   "source": [
    "# Pre-process data \n",
    "The goal here is to end up with an array of data that will be ingested by the classifier. Probably we will start with `training_data` and then add some other properties that we think are potentially relevant.\n",
    "\n",
    "Note that the same procedure needs to be applied to the validation data and the test data. Also, keep in mind not to add the \"truth\" into the training array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e757efd-ff2d-4f08-a9f9-8b5087759635",
   "metadata": {
    "id": "6e757efd-ff2d-4f08-a9f9-8b5087759635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3450643, 122) X_train size\n",
      "(3450643,) y_train size\n",
      "(739420, 122) X_validation size\n",
      "(739420,) y_validation size\n",
      "(739435, 122) X_test shape\n",
      "(739435,) y_test shape\n",
      "(52020, 122) X_real shape\n",
      "(52020,) y_real shape\n",
      "<class 'numpy.ndarray'> training data\n",
      "<class 'numpy.ndarray'> training properties\n"
     ]
    }
   ],
   "source": [
    "X_train = training_data[:, :, 1:]  # Only consider columns 1 and 2, since 0 is the flux without noise, not realistic\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)  # Shape (n,114)\n",
    "y_train = training_properties_df[\"SPECTYPE\"].to_numpy()\n",
    "# From 3D to 2D data so we can work on it\n",
    "X_validation = validation_data[:, :, 1:]          \n",
    "X_validation = X_validation.reshape(X_validation.shape[0], -1)\n",
    "y_validation = validation_properties_df[\"SPECTYPE\"].to_numpy()\n",
    "X_test = test_data[:, :, 1:]          \n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "y_test = test_properties_df[\"SPECTYPE\"].to_numpy()\n",
    "\n",
    "# Real data have different structure: \n",
    "real_data_flux1 = real_data['FLUX_APER_COR_3_0']\n",
    "real_data_flux2 = real_data['FLUX_RELERR_APER_COR_3_0']\n",
    "X_real = np.concatenate([real_data_flux1, real_data_flux2], axis=1)\n",
    "y_real = real_properties_df[\"SPECTYPE\"].to_numpy()\n",
    "\n",
    "\n",
    "# Now we will take some columns from y_train and also use them to train the model, \n",
    "# that is, we will include them inside X_train. \n",
    "# Therefore, y_train will only keep the correct target, which will remain the 'spectype' column.\n",
    "# We will select the columns that might provide useful information: \n",
    "# RA, DEC, DESI_FLUX_G, DESI_FLUX_R, DESI_FLUX_Z, EBV, MORPHTYPE, NOISE_SEED, NOISE_TILE. \n",
    "# First, we take these columns into a variable:\n",
    "\n",
    "# To include the 'morphtype' column, we need to transform its values from letters to numbers.\n",
    "training_properties_df[['MORPHTYPE']]\n",
    "# To incorporate the new columns:\n",
    "morph_map = {label: idx + 1 for idx, label in enumerate(training_properties_df['MORPHTYPE'].unique())}\n",
    "training_properties_df['MORPHTYPE'] = training_properties_df['MORPHTYPE'].map(morph_map)\n",
    "\n",
    "# 2. Create the new array with the additional columns\n",
    "new_props = training_properties_df[['RA', 'DEC', 'DESI_FLUX_G', 'DESI_FLUX_R', 'DESI_FLUX_Z', 'EBV', 'MORPHTYPE', 'NOISE_TILE']].to_numpy()\n",
    "\n",
    "# 3. Concatenate with X_train\n",
    "X_train = np.concatenate([X_train, new_props], axis=1)\n",
    "\n",
    "# 1. Encode 'MORPHTYPE' in each dataframe (using the same morph_map as in training)\n",
    "validation_properties_df['MORPHTYPE'] = validation_properties_df['MORPHTYPE'].map(morph_map)\n",
    "test_properties_df['MORPHTYPE'] = test_properties_df['MORPHTYPE'].map(morph_map)\n",
    "real_properties_df['MORPHTYPE'] = real_properties_df['MORPHTYPE'].map(morph_map)\n",
    "\n",
    "# 2. Add the new columns to each dataset\n",
    "cols = ['RA','DEC','DESI_FLUX_G','DESI_FLUX_R','DESI_FLUX_Z','EBV','MORPHTYPE','NOISE_TILE']\n",
    "\n",
    "# Validation\n",
    "new_props_val = validation_properties_df[cols].to_numpy()\n",
    "X_validation = np.concatenate([X_validation, new_props_val], axis=1)\n",
    "\n",
    "# Test\n",
    "new_props_test = test_properties_df[cols].to_numpy()\n",
    "X_test = np.concatenate([X_test, new_props_test], axis=1)\n",
    "\n",
    "# Real\n",
    "new_props_real = real_properties_df[cols].to_numpy()\n",
    "X_real = np.concatenate([X_real, new_props_real], axis=1)\n",
    "\n",
    "\n",
    "# Check the shape and size of the data.\n",
    "print(X_train.shape,\"X_train size\")\n",
    "print(y_train.shape,\"y_train size\")\n",
    "print(X_validation.shape, \"X_validation size\")\n",
    "print(y_validation.shape, \"y_validation size\")\n",
    "print(X_test.shape, \"X_test shape\")\n",
    "print(y_test.shape, \"y_test shape\")\n",
    "print(X_real.shape, \"X_real shape\")\n",
    "print(y_real.shape, \"y_real shape\")\n",
    "\n",
    "print(type(X_train),\"training data\")\n",
    "print(type(y_train),\"training properties\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681ef9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3448443, 122) X_train netejat\n",
      "(3448443, 1) y_train netejat\n",
      "(738964, 122) X_validation netejat\n",
      "(738964, 1) y_validation netejat\n",
      "(738944, 122) X_test netejat\n",
      "(738944, 1) y_test netejat\n",
      "(52020, 122) X_real netejat\n",
      "(52020, 1) y_real netejat\n"
     ]
    }
   ],
   "source": [
    "# Here we will check if there are any null values in the different data columns.\n",
    "\n",
    "# Clean the training data\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "null_rows_X_train = X_train_df.isnull().any(axis=1)\n",
    "null_rows_y_train = y_train_df.isnull().any(axis=1)\n",
    "\n",
    "posicions_nan_X_train = null_rows_X_train[null_rows_X_train].index\n",
    "posicions_nan_y_train = null_rows_y_train[null_rows_y_train].index\n",
    "\n",
    "posicions_nan_totals_train = set(posicions_nan_X_train).union(set(posicions_nan_y_train))\n",
    "\n",
    "X_train_df_null = X_train_df.iloc[list(posicions_nan_totals_train)]\n",
    "\n",
    "X_train_net = X_train_df.drop(index=posicions_nan_totals_train)\n",
    "y_train_net = y_train_df.drop(index=posicions_nan_totals_train)\n",
    "\n",
    "X_train = X_train_net.to_numpy()\n",
    "y_train = y_train_net.to_numpy()\n",
    "\n",
    "\n",
    "# Clean the validation data\n",
    "X_validation_df = pd.DataFrame(X_validation)\n",
    "y_validation_df = pd.DataFrame(y_validation)\n",
    "\n",
    "null_rows_X_val = X_validation_df.isnull().any(axis=1)\n",
    "null_rows_y_val = y_validation_df.isnull().any(axis=1)\n",
    "\n",
    "posicions_nan_X_val = null_rows_X_val[null_rows_X_val].index\n",
    "posicions_nan_y_val = null_rows_y_val[null_rows_y_val].index\n",
    "\n",
    "posicions_nan_totals_val = set(posicions_nan_X_val).union(set(posicions_nan_y_val))\n",
    "\n",
    "X_validation_net = X_validation_df.drop(index=posicions_nan_totals_val)\n",
    "y_validation_net = y_validation_df.drop(index=posicions_nan_totals_val)\n",
    "\n",
    "X_validation = X_validation_net.to_numpy()\n",
    "y_validation = y_validation_net.to_numpy()\n",
    "\n",
    "# Clean the test data\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "null_rows_X_test = X_test_df.isnull().any(axis=1)\n",
    "null_rows_y_test = y_test_df.isnull().any(axis=1)\n",
    "\n",
    "posicions_nan_X_test = null_rows_X_test[null_rows_X_test].index\n",
    "posicions_nan_y_test = null_rows_y_test[null_rows_y_test].index\n",
    "\n",
    "posicions_nan_totals_test = set(posicions_nan_X_test).union(set(posicions_nan_y_test))\n",
    "\n",
    "X_test_net = X_test_df.drop(index=posicions_nan_totals_test)\n",
    "y_test_net = y_test_df.drop(index=posicions_nan_totals_test)\n",
    "\n",
    "X_test = X_test_net.to_numpy()\n",
    "y_test = y_test_net.to_numpy()\n",
    "\n",
    "# Clean the real data\n",
    "X_real_df = pd.DataFrame(X_real)\n",
    "y_real_df = pd.DataFrame(y_real)\n",
    "\n",
    "null_rows_X_real = X_real_df.isnull().any(axis=1)\n",
    "null_rows_y_real = y_real_df.isnull().any(axis=1)\n",
    "\n",
    "posicions_nan_X_real = null_rows_X_real[null_rows_X_real].index\n",
    "posicions_nan_y_real = null_rows_y_real[null_rows_y_real].index\n",
    "\n",
    "posicions_nan_totals_real = set(posicions_nan_X_real).union(set(posicions_nan_y_real))\n",
    "\n",
    "X_real_df_null = X_real_df.iloc[list(posicions_nan_totals_real)]\n",
    "\n",
    "X_real_net = X_real_df.drop(index=posicions_nan_totals_real)\n",
    "y_real_net = y_real_df.drop(index=posicions_nan_totals_real)\n",
    "\n",
    "X_real = X_real_net.to_numpy()\n",
    "y_real = y_real_net.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape, \"X_train netejat\")\n",
    "print(y_train.shape, \"y_train netejat\")\n",
    "print(X_validation.shape, \"X_validation netejat\")\n",
    "print(y_validation.shape, \"y_validation netejat\")\n",
    "print(X_test.shape, \"X_test netejat\")\n",
    "print(y_test.shape, \"y_test netejat\")\n",
    "print(X_real.shape, \"X_real netejat\")\n",
    "print(y_real.shape, \"y_real netejat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691aa629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we scale the data to optimize the model, improving convergence and accuracy.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_real = scaler.transform(X_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaacb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qso = []\n",
    "n_gal = []\n",
    "n_star = []\n",
    "\n",
    "for index, item in enumerate(y_train):\n",
    "    if item == 'QSO':\n",
    "        n_qso.append(item)\n",
    "    elif item == 'GALAXY':\n",
    "        n_gal.append(item)\n",
    "    elif item == 'STAR':\n",
    "        n_star.append(item)\n",
    "\n",
    "print(len(n_qso))\n",
    "print(len(n_gal))\n",
    "print(len(n_star))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94899e92-1d2e-4e4d-8602-200cfe859012",
   "metadata": {
    "id": "94899e92-1d2e-4e4d-8602-200cfe859012"
   },
   "source": [
    "# Define and train the algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232502ca-0a96-4263-b547-c677604546d0",
   "metadata": {
    "id": "232502ca-0a96-4263-b547-c677604546d0"
   },
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "weights_dict = {'GALAXY': 1.0, 'STAR': 1, 'QSO': 4} #star: 4, qso: 30\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=54723, bootstrap= False, max_depth = 40, min_samples_leaf=3, min_samples_split = 4, class_weight=weights_dict,  n_jobs=-1)\n",
    "print(\"Training\")\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "print(\"Done\")\n",
    "\n",
    "#split: 50, 200, 1000\n",
    "#leaf: 20, 50, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d28578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent (SGD)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "weights_dict = {'GALAXY': 1.0, 'STAR': 2, 'QSO': 6}\n",
    "sgdc = SGDClassifier(loss='log_loss', penalty='elasticnet', alpha=1e-4, max_iter=80000, early_stopping=True, learning_rate='adaptive', eta0=0.01,  tol=1e-3, class_weight=weights_dict, random_state=13432)\n",
    "\n",
    "sgdc.fit(X_train, y_train.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48168d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transform the data so they can be used to train a neural network. y_train cannot contain string elements; they must be numbers.\n",
    "# We assign 0 to a quasar, 1 to a star, and 2 to a galaxy.\n",
    "\n",
    "y_train_xn = []\n",
    "for index, item in enumerate(y_train):\n",
    "    if item == 'QSO':\n",
    "        y_train_xn.append(0)\n",
    "    elif item == 'GALAXY':\n",
    "        y_train_xn.append(2)\n",
    "    elif item == 'STAR':\n",
    "        y_train_xn.append(1)\n",
    "print(y_train_xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d3f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network (MLP)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Number of samples we want (50% of the total)\n",
    "n_samples = int(len(X_train) * 0.5)\n",
    "\n",
    "# Get random indices\n",
    "np.random.seed(23)  \n",
    "random_indices = np.random.choice(len(X_train), size=n_samples, replace=False)\n",
    "\n",
    "# Take only these indexs\n",
    "X_train_fitxn = X_train[random_indices]\n",
    "y_train_xn = np.array(y_train_xn)\n",
    "y_train_fitxn = y_train_xn[random_indices]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate classes\n",
    "qso_samples = X_train_fitxn[y_train_fitxn == 0]  # Class 'qso' (0)\n",
    "galaxy_samples = X_train_fitxn[y_train_fitxn == 2]\n",
    "star_samples = X_train_fitxn[y_train_fitxn == 1]\n",
    "\n",
    "# Multiplies quasars 30 times (equivalent to weight=30)\n",
    "qso_oversampled = resample(qso_samples, replace=True, n_samples=1*len(qso_samples))\n",
    "\n",
    "# Combine the oversampled data\n",
    "X_train_balanced = np.concatenate([qso_oversampled, galaxy_samples, star_samples])\n",
    "y_train_balanced = np.concatenate([\n",
    "    np.zeros(len(qso_oversampled)),      # Tag 0 (qso)\n",
    "    2*np.ones(len(galaxy_samples)),      # Tag 2 (galaxy)\n",
    "    np.ones(len(star_samples))           # Tag 1 (star)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the neural network classifier (Multi-layer Perceptron, MLP)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),  # Hidden layer (n_neurons, n_layers)\n",
    "    activation='relu',          # Activation function for hidden layer\n",
    "    solver='adam',              # Optimize steps\n",
    "    alpha=1e-5,               # L2 regularization parameter to prevent overfitting\n",
    "    batch_size='auto',          \n",
    "    learning_rate='constant',   # Learning rate ('constant', 'invscaling', 'adaptive')\n",
    "    learning_rate_init=0.0005,   # Initial learning rate\n",
    "    max_iter=3000,              # Max number of iterations\n",
    "    random_state=7324,          \n",
    "    verbose=False,              # To show or not the training process\n",
    "    early_stopping=True,        # Stop training if validation is not improving\n",
    "    validation_fraction=0.1,    # Proportion of training data to use as validation set\n",
    "    n_iter_no_change=20,         # Number of epochs without improvement before stopping\n",
    "\n",
    "    tol = 1e-5\n",
    ")\n",
    "\n",
    "# Train the neural network with the scaled data\n",
    "mlp.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_pred_mlp = mlp.predict(X_validation)\n",
    "\n",
    "\n",
    "# Evaluate the model performance\n",
    "#print(\"Matriu de Confusió:\\n\", confusion_matrix(y_test, y_pred_mlp))\n",
    "#print(\"\\nInforme de Classificació:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19cee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppose you have the column names available:\n",
    "X_train_df = pd.DataFrame(X_train[:, :-7])  # If you have concatenated .csv data afterwards\n",
    "news = training_properties_df[['RA','DEC','DESI_FLUX_G','DESI_FLUX_R','DESI_FLUX_Z','EBV','NOISE_TILE']] \n",
    "modif = pd.concat([X_train_df, news], axis=1)\n",
    "caract_importants = list(modif.columns)\n",
    "\n",
    "# Get the weights of the first layer of the MLP\n",
    "# mlp.coefs_ is a list: each element is a weight matrix between layers\n",
    "# mlp.coefs_[0]: weights between input and first hidden layer\n",
    "# Calculate the absolute value of the weights and average for each feature\n",
    "\n",
    "primeres_pesos = mlp.coefs_[0]  # shape = (n_features, n_hidden_neurons)\n",
    "importancies = np.mean(np.abs(primeres_pesos), axis=1)\n",
    "\n",
    "# Convert to a pandas Series for sorting and visualization\n",
    "mlp_importances = pd.Series(importancies, index=caract_importants)\n",
    "mlp_importances = mlp_importances.sort_values(ascending=False)\n",
    "\n",
    "# Plot general\n",
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "mlp_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Importància de les característiques segons MLP (mitjana |pesos| primera capa)\")\n",
    "ax.set_ylabel(\"MLP weights\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# # Define a threshold to consider features as \"important\"\n",
    "threshold = 0.45\n",
    "importants = mlp_importances[mlp_importances >= threshold]\n",
    "less_importants = mlp_importances[mlp_importances < threshold]\n",
    "\n",
    "# Plots separated\n",
    "if not importants.empty:\n",
    "    fig1, ax1 = plt.subplots(figsize=(6, 3))\n",
    "    importants.plot.bar(ax=ax1, color=\"tab:blue\")\n",
    "    ax1.set_title(\"Features with weights ≥ 0.5\")\n",
    "    ax1.set_ylabel(\"MLP weights\")\n",
    "    fig1.tight_layout()\n",
    "else:\n",
    "    print(\"Cap feature amb importància ≥ 0.02\")\n",
    "\n",
    "if not less_importants.empty:\n",
    "    fig2, ax2 = plt.subplots(figsize=(6,3))\n",
    "    less_importants.plot.bar(ax=ax2, color=\"tab:orange\")\n",
    "    ax2.set_title(\"\")\n",
    "    ax2.set_ylabel(\"MLP weights\")\n",
    "    fig2.tight_layout()\n",
    "else:\n",
    "    print(\"Cap feature amb importància < 0.02\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a749ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(100,50)], \n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'learning_rate': ['constant']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(mlp, param_dist, n_iter=20, cv=5, scoring='f1_macro', random_state=42)\n",
    "random_search.fit(X_train_fitxn, y_train_fitxn)\n",
    "\n",
    "print(\"Millors paràmetres:\", random_search.best_params_)\n",
    "best_model_xn = random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data back to the labels 'GALAXY', 'QSO', and 'STAR'\n",
    "\n",
    "y_pred_xn = []\n",
    "for index, item in enumerate(y_pred_mlp):\n",
    "    if item == 0:\n",
    "        y_pred_xn.append('QSO')\n",
    "    elif item == 2:\n",
    "        y_pred_xn.append('GALAXY')\n",
    "    elif item == 1:\n",
    "        y_pred_xn.append('STAR')\n",
    "print(y_pred_xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a403f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the best parameters for the Random Forest, first define a function that searches for them in the quasar evaluation case:\n",
    "from sklearn.metrics import f1_score\n",
    "def funcio_qso_scoring(estimator, X, y):\n",
    "    \"\"\"Hola\"\"\"\n",
    "\n",
    "    y_pred = estimator.predict(X)\n",
    "    \n",
    "    y_isqso = ['QSO' if item == 'QSO' else 'NOT_QSO' for item in y]\n",
    "    y_notqso = ['QSO' if item == 'QSO' else 'NOT_QSO' for item in y_pred]\n",
    "    \n",
    "    return f1_score(y_isqso, y_notqso, average = 'binary', pos_label='QSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we search for the best parameters of the Random Forest (hyperparameter tuning) to achieve the best accuracy.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Number of samples you want (20% of the total)\n",
    "n_samples = int(len(X_train) * 0.2)\n",
    "\n",
    "# Get random indices\n",
    "np.random.seed(23)\n",
    "random_indices = np.random.choice(len(X_train), size=n_samples, replace=False)\n",
    "\n",
    "# Agafar només aquests índexs\n",
    "X_train_grid_rf = X_train[random_indices]\n",
    "y_train_grid_rf = y_train[random_indices]\n",
    "\n",
    "\n",
    "# RANDOM FOREST:\n",
    "# Define the parameters we want to tune for the Random Forest:\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5],\n",
    "    'max_depth': [None], # Tree depth (number of questions it can ask)\n",
    "    'min_samples_split': [4, 5], # Used to split the data into an appropriate number of samples.\n",
    "    'min_samples_leaf': [2, 3], # Minimum number of samples each branch must have; if not met, the split is not performed.\n",
    "    'bootstrap': [False], # Whether the training data has repetitions (True) or no repetitions (False)\n",
    "# 'max_features': ['sqrt', 'log2', None], # Number of features to consider when looking for the best split.\n",
    "# 'oob_score': [True, False], # Only works if bootstrap=True\n",
    "# 'random_state': [54723],\n",
    "\n",
    "    'class_weight': [None, 'balanced'], # Balanced is used to give more importance to the class with fewer samples (like quasars)\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV (cv splits the data into X parts and performs 5 different trainings. It helps prevent overfitting)\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring=funcio_qso_scoring, n_jobs=-1, verbose=2) #Afegim scoring='f1_macro' per si volem millorar f1-score i no accuracy.\n",
    "\n",
    "# Train model\n",
    "grid_search.fit(X_train_grid_rf, y_train_grid_rf)\n",
    "\n",
    "# Results of the best model\n",
    "print(\"Millors paràmetres trobats pel RandomForest: \", grid_search.best_params_)\n",
    "print(\"Precissió del millor model pel RandomForest: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "# Avaluate the best model with test data:\n",
    "best_model_rf = grid_search.best_estimator_\n",
    "\n",
    "test_accuracy = best_model_rf.score(X_test, y_test)\n",
    "print(\"Precissió en el conjunt de test: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from optuna.samplers import GridSampler\n",
    "\n",
    "# Number of samples you want (20% of the total) (same as before)\n",
    "n_samples = int(len(X_train) * 0.2)\n",
    "np.random.seed(19)\n",
    "random_indices = np.random.choice(len(X_train), size=n_samples, replace=False)\n",
    "X_train_grid_rf = X_train[random_indices]\n",
    "y_train_grid_rf = y_train[random_indices]\n",
    "\n",
    "# Define the search space IDENTICAL to the original grid search\n",
    "weights_dict = {'GALAXY': 1.0, 'STAR': 1.0, 'QSO': 10}\n",
    "search_space = {\n",
    "    'n_estimators': [25],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [4, 10, 50, 200],\n",
    "    'min_samples_leaf': [8, 20, 100, 300, 1000],\n",
    "    'bootstrap': [False],\n",
    "    'class_weight': [weights_dict],\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', search_space['n_estimators']),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', search_space['max_depth']),\n",
    "        'min_samples_split': trial.suggest_categorical('min_samples_split', search_space['min_samples_split']),\n",
    "        'min_samples_leaf': trial.suggest_categorical('min_samples_leaf', search_space['min_samples_leaf']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', search_space['bootstrap']),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', search_space['class_weight']),\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**params)\n",
    "    scores = cross_val_score(\n",
    "        estimator=model,\n",
    "        X=X_train_grid_rf,\n",
    "        y=y_train_grid_rf,\n",
    "        cv=5,\n",
    "        scoring=funcio_qso_scoring,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return scores.mean()\n",
    "\n",
    "# Create the study with GridSampler for exhaustive search\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=GridSampler(search_space)\n",
    ")\n",
    "\n",
    "# Calculate the total number of combinations\n",
    "n_trials = 1\n",
    "for v in search_space.values():\n",
    "    n_trials *= len(v)\n",
    "\n",
    "# Execute the search\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# Results\n",
    "print(\"Millors paràmetres trobats pel RandomForest:\", study.best_params)\n",
    "print(\"Precissió del millor model:\", study.best_value)\n",
    "\n",
    "# Train the best model with all the subset data\n",
    "best_model_rf = RandomForestClassifier(**study.best_params)\n",
    "best_model_rf.fit(X_train_grid_rf, y_train_grid_rf)\n",
    "\n",
    "# Avaluate with test\n",
    "test_accuracy = best_model_rf.score(X_test, y_test)\n",
    "print(\"Precissió en el conjunt de test:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478aa4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will look at which data-type columns are the most important when making predictions with the RandomForest.\n",
    "\n",
    "importance = clf.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]  # Sort from most important to least important feature\n",
    "\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train[:, :-7])\n",
    "news = training_properties_df[['RA','DEC','DESI_FLUX_G','DESI_FLUX_R','DESI_FLUX_Z','EBV','NOISE_TILE']] \n",
    "modif = pd.concat([X_train_df, news], axis = 1)\n",
    "caract_importants = list(modif.columns)\n",
    "\n",
    "\n",
    "ordre_importancia = []\n",
    "for index, item in enumerate(indices):\n",
    "    ordre_importancia.append(caract_importants[item])\n",
    "\n",
    "#print(ordre_importancia)\n",
    "# It gives us the most important columns, but we see that they are from the filters and not the ones we extracted from the .csv.\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#feature_names = [f\"feature {i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "start_time = time.time()\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "\n",
    "forest_importances = pd.Series(importance, index=ordre_importancia)\n",
    "forest_importances = forest_importances.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "# Before finishing this section, we could use an \"if\" statement to select only those samples that allow a higher (or lower) mean decrease in impurity\n",
    "# to see which columns enable greater (or lesser) accuracy.\n",
    "\n",
    "\n",
    "# Threshold\n",
    "threshold = 0.012\n",
    "\n",
    "# Separate the features into two series based on the threshold\n",
    "importants = forest_importances[forest_importances >= threshold]\n",
    "less_importants = forest_importances[forest_importances < threshold]\n",
    "\n",
    "# Same for the stds\n",
    "std_series = pd.Series(std, index=ordre_importancia)\n",
    "std_importants = std_series[importants.index]\n",
    "std_less_importants = std_series[less_importants.index]\n",
    "\n",
    "#Figure 1: important features\n",
    "if not importants.empty:\n",
    "    fig1, ax1 = plt.subplots(figsize=(6, 3))\n",
    "    importants.plot.bar(yerr=std_importants, ax=ax1, color=\"tab:blue\")\n",
    "    ax1.set_title(\"Features with MDI ≥ 0.01\")\n",
    "    ax1.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig1.tight_layout()\n",
    "else:\n",
    "    print(\"Cap feature amb importància ≥ 0.02\")\n",
    "\n",
    "#Figura 2: less important features\n",
    "if not less_importants.empty:\n",
    "    fig2, ax2 = plt.subplots(figsize=(6, 3))\n",
    "    less_importants.plot.bar(yerr=std_less_importants, ax=ax2, color=\"tab:orange\")\n",
    "    ax2.set_title(\"Features amb importància < 0.02\")\n",
    "    ax2.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig2.tight_layout()\n",
    "else:\n",
    "    print(\"Cap feature amb importància < 0.02\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02685068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for SGD, searching for the best model with the best SGD parameters.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Number of samples you want (10% of the total)\n",
    "n_samples = int(len(X_train) * 0.4)\n",
    "\n",
    "# Get random indices\n",
    "np.random.seed(42)  \n",
    "random_indices = np.random.choice(len(X_train), size=n_samples, replace=False)\n",
    "\n",
    "# Only these indices\n",
    "X_train_grid_sgd = X_train[random_indices]\n",
    "y_train_grid_sgd = y_train[random_indices]\n",
    "\n",
    "#Pipeline with StandardScaler and the classifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sgd', SGDClassifier(random_state=1111))\n",
    "])\n",
    "\n",
    "# Define the parameters to try\n",
    "param_grid = {\n",
    "    'sgd__loss': ['hinge', 'log_loss'], #'modified_huber'\n",
    "    'sgd__penalty': ['l2', 'elasticnet'],\n",
    "    'sgd__alpha': [1e-4],\n",
    "    'sgd__max_iter': [5000],\n",
    "    'sgd__tol': [ 1e-6],\n",
    "    'sgd__class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=funcio_qso_scoring, n_jobs=1)\n",
    "\n",
    "# Train the model\n",
    "grid_search.fit(X_train_grid_sgd, y_train_grid_sgd.ravel())\n",
    "\n",
    "# Best parameters found\n",
    "print(\"Millors paràmetres trobats:\",grid_search.best_params_)\n",
    "\n",
    "# Best score\n",
    "print(\"Millor accuracy de validació:\",grid_search.best_score_)\n",
    "\n",
    "# Best model\n",
    "best_model_sgd = grid_search.best_estimator_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from optuna.samplers import GridSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Subset of 20%\n",
    "n_samples = int(len(X_train) * 0.2)\n",
    "np.random.seed(19)\n",
    "random_indices = np.random.choice(len(X_train), size=n_samples, replace=False)\n",
    "X_train_grid_sgd = X_train[random_indices]\n",
    "y_train_grid_sgd = y_train[random_indices].ravel()\n",
    "\n",
    "search_space = {\n",
    "    'sgd__loss': ['log_loss', 'modified_huber'],\n",
    "    'sgd__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'sgd__alpha': [1e-4],\n",
    "    'sgd__max_iter': [10000],\n",
    "    'sgd__tol': [1e-3],\n",
    "    'sgd__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'sgd__loss': trial.suggest_categorical('sgd__loss', search_space['sgd__loss']),\n",
    "        'sgd__penalty': trial.suggest_categorical('sgd__penalty', search_space['sgd__penalty']),\n",
    "        'sgd__alpha': trial.suggest_categorical('sgd__alpha', search_space['sgd__alpha']),\n",
    "        'sgd__max_iter': trial.suggest_categorical('sgd__max_iter', search_space['sgd__max_iter']),\n",
    "        'sgd__tol': trial.suggest_categorical('sgd__tol', search_space['sgd__tol']),\n",
    "        'sgd__class_weight': trial.suggest_categorical('sgd__class_weight', search_space['sgd__class_weight']),\n",
    "    }\n",
    "\n",
    "    sgd_params = {k.replace('sgd__', ''): v for k, v in params.items()}\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('sgd', SGDClassifier(random_state=1111, **sgd_params))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        estimator=pipeline,\n",
    "        X=X_train_grid_sgd,\n",
    "        y=y_train_grid_sgd,\n",
    "        cv=5,\n",
    "        scoring=funcio_qso_scoring,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    return scores.mean()\n",
    "\n",
    "# Number of combinations\n",
    "n_trials = 1\n",
    "for v in search_space.values():\n",
    "    n_trials *= len(v)\n",
    "\n",
    "print(n_trials)\n",
    "\n",
    "# Study\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=GridSampler(search_space)\n",
    ")\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# Results\n",
    "print(\"Millors paràmetres:\", study.best_params)\n",
    "print(\"Millor accuracy validació:\", study.best_value)\n",
    "\n",
    "# Final training\n",
    "best_sgd_params = {k.replace('sgd__', ''): v for k, v in study.best_params.items()}\n",
    "best_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sgd', SGDClassifier(random_state=1111, **best_sgd_params))\n",
    "]).fit(X_train_grid_sgd, y_train_grid_sgd)\n",
    "\n",
    "# Test\n",
    "test_accuracy = best_pipeline.score(X_test, y_test)\n",
    "print(\"Precisió test:\", test_accuracy)\n",
    "#[I 2025-05-13 01:14:09,779] Trial 1 finished with value: 0.13843365468666272 and parameters: {'sgd__loss': 'hinge', 'sgd__penalty': 'l2', 'sgd__alpha': 1e-05, 'sgd__max_iter': 9000, 'sgd__tol': 1e-06, 'sgd__class_weight': 'balanced'}. Best is trial 1 with value: 0.13843365468666272.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6444b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Since SGD is not a tree-based model like Random Forest, we cannot use the MDI metric. Therefore, we will determine the importance of each column by looking \n",
    "# at the weights assigned to each feature, i.e., each column, when making predictions. In this way, the weights help us determine the importance of each column.\n",
    "\n",
    "# Get the coefficients of the trained model\n",
    "coeficients = np.mean(np.abs(sgdc.coef_), axis=0) #Agafem els pesos de la mitjana de la classificació de les 3 classes d'aquesta manera per fer una mitjana dels pesos assignats. \n",
    "\n",
    "# We take the feature (column) names as we did before with the Random Forest\n",
    "X_train_df = pd.DataFrame(X_train[:, :-7])\n",
    "news = training_properties_df[['RA','DEC','DESI_FLUX_G','DESI_FLUX_R','DESI_FLUX_Z','EBV','NOISE_TILE']] \n",
    "modif = pd.concat([X_train_df, news], axis=1)\n",
    "caract_importants = list(modif.columns)\n",
    "\n",
    "# Convert to a pandas Series for sorting:\n",
    "sgd_importances = pd.Series(np.abs(coeficients), index=caract_importants)\n",
    "\n",
    "# Sort from most to least important\n",
    "sgd_importances = sgd_importances.sort_values(ascending=False)\n",
    "\n",
    "# Plot the most important columns\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "sgd_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Importància de les característiques segons SGD (valors absoluts dels coeficients)\")\n",
    "ax.set_ylabel(\"Coeficient absolut\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# As we did before, we will separate the features into more or less important according to the following threshold:\n",
    "threshold = 2.25  \n",
    "importants = sgd_importances[sgd_importances >= threshold]\n",
    "less_importants = sgd_importances[sgd_importances < threshold]\n",
    "\n",
    "# Take the most important ones, those whose weights are greater than 0.1, the threshold value.\n",
    "if not importants.empty:\n",
    "    fig1, ax1 = plt.subplots(figsize=(6,3))\n",
    "    importants.plot.bar(ax=ax1, color=\"tab:blue\")\n",
    "    ax1.set_title(\"Feagures with weights ≥ 2.25\")\n",
    "    ax1.set_ylabel(\"Weights\")\n",
    "    fig1.tight_layout()\n",
    "else:\n",
    "    print(\"Cap feature amb importància ≥ 0.1\")\n",
    "\n",
    "# For the less important ones\n",
    "if not less_importants.empty:\n",
    "    fig2, ax2 = plt.subplots(figsize=(6,3))\n",
    "    less_importants.plot.bar(ax=ax2, color=\"tab:orange\")\n",
    "    ax2.set_title(\"\")\n",
    "    ax2.set_ylabel(\"Weights of each feature\")\n",
    "    fig2.tight_layout()\n",
    "else:\n",
    "    print(\"Cap feature amb importància < 0.1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3fa761-444d-475a-952a-eec5424169e5",
   "metadata": {
    "id": "bc3fa761-444d-475a-952a-eec5424169e5"
   },
   "source": [
    "# Predict on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b32420-f44b-48be-834b-3abbb593e285",
   "metadata": {
    "id": "65b32420-f44b-48be-834b-3abbb593e285"
   },
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "y_pred_rf = clf.predict(X_validation)  \n",
    "probs_pred = clf.predict_proba(X_validation)  \n",
    "print(y_pred_rf.shape,\"y_pred shape\")\n",
    "print(X_validation.shape,\"X_validation shape\")\n",
    "\n",
    "#y_pred_brf = best_model_rf.predict(X_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest with real data\n",
    "y_pred_rf_real = clf.predict(X_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0567c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "y_pred_sgd = sgdc.predict(X_validation)\n",
    "#probs_pred = sgdc.predict_proba(X_validation) #Si voleu les probs_pred hem de fer servir loss = log_loss, ja que hinge no funciona en aquest cas.\n",
    "print(y_pred_sgd.shape,\"y_pred shape\")\n",
    "\n",
    "#y_pred_bsgd = best_model_sgd.predict(X_validation)\n",
    "y_pred_sgd_real = sgdc.predict(X_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18026792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will filter the prediction results for only the quasar cases.\n",
    "quas_predict_rf = [] # Predictions that include whether it predicted quasar correctly, predicted quasar but it was not, or was quasar but not predicted.\n",
    "quas_data_rf = [] \n",
    "quas_predict_brf = []  \n",
    "quas_data_brf = []\n",
    "quas_predict_sgd = []\n",
    "quas_data_sgd = []\n",
    "quas_predict_bsgd = []\n",
    "quas_data_bsgd = []\n",
    "quas_predict_xn = []\n",
    "quas_data_xn = []\n",
    "\n",
    "'''\n",
    "for index, item in enumerate(y_pred_rf):\n",
    "    quas_valid = y_validation[index]\n",
    "\n",
    "    if quas_valid == 'QSO' or item == 'QSO':\n",
    "        quas_predict_rf.append(item)\n",
    "        quas_data_rf.append(y_validation[index])\n",
    "\n",
    "\n",
    "for index, item in enumerate(y_pred_brf):\n",
    "    quas_valid = y_validation[index]\n",
    "    \n",
    "    if quas_valid == 'QSO' or item == 'QSO':\n",
    "        quas_predict_brf.append(item)\n",
    "        quas_data_brf.append(y_validation[index])\n",
    "'''  \n",
    "        \n",
    "\n",
    "for index, item in enumerate(y_pred_sgd):\n",
    "    quas_valid = y_validation[index]\n",
    "    \n",
    "    if quas_valid == 'QSO' or item == 'QSO':\n",
    "        quas_predict_sgd.append(item)\n",
    "        quas_data_sgd.append(y_validation[index])\n",
    "        \n",
    "for index, item in enumerate(y_pred_bsgd):\n",
    "    quas_valid = y_validation[index]\n",
    "    \n",
    "    if quas_valid == 'QSO' or item == 'QSO':\n",
    "        quas_predict_bsgd.append(item)\n",
    "        quas_data_bsgd.append(y_validation[index])\n",
    "\n",
    "\n",
    "'''\n",
    "for index, item in enumerate(y_pred_xn):\n",
    "    quas_valid = y_validation[index]\n",
    "    \n",
    "    if quas_valid == 'QSO' or item == 'QSO':\n",
    "        quas_predict_xn.append(item)\n",
    "        quas_data_xn.append(y_validation[index])\n",
    "'''\n",
    " \n",
    "\"\"\"\n",
    "for index, item in enumerate(y_train):\n",
    "    if item == 'QSO':\n",
    "        X_train_qso.append(X_train[index])  # Afegim la fila corresponent de X_train\n",
    "\n",
    "# Convertim la llista a un ndarray de NumPy\n",
    "X_train_qso = np.array(X_train_qso)\n",
    "#print(X_train_qso.shape)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d997d0c7-dc62-40ce-a1cd-f2964082bba2",
   "metadata": {
    "id": "d997d0c7-dc62-40ce-a1cd-f2964082bba2"
   },
   "source": [
    "# Evaluate the performance\n",
    "Here you should check `y_pred` against `y_validation` to estimate the performance. There are several metrics to choose from: purity, completeness. F1-score is usually a good summary metric.\n",
    "\n",
    "Possibly you can evaluate the metric for certain subgroups (e.g. magnitude bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9da349-ca22-41ee-af71-6a238500b2ee",
   "metadata": {
    "id": "cf9da349-ca22-41ee-af71-6a238500b2ee"
   },
   "outputs": [],
   "source": [
    "fallos = []\n",
    "resposta = []\n",
    "for index, item in enumerate(y_pred_rf):\n",
    "        if item != y_validation[index]:\n",
    "            fallos.append(item)\n",
    "            resposta.append(y_validation[index])\n",
    "\n",
    "print(len(fallos))\n",
    "print(len(resposta))\n",
    "\n",
    "\n",
    "\n",
    "fallos = []\n",
    "resposta = []\n",
    "for index, item in enumerate(y_pred_brf):\n",
    "        if item != y_validation[index]:\n",
    "            fallos.append(item)\n",
    "            resposta.append(y_validation[index])\n",
    "\n",
    "print(len(fallos))\n",
    "print(len(resposta))\n",
    "\n",
    "# Metrics such as purity, F1-score, etc. still need to be defined, but this code allows us to get an idea of the cases the model failed and how many errors occurred for each different number of estimators set in n_estimators.\n",
    "# Specifically, for n_estimators = 40 we have 24,906 errors, for n_estimators = 20, we have 26,069 errors, and for n_estimators = 50 we have 24,494 errors. We haven't tested more due to long execution times.\n",
    "# In this code, the \"fallos\" list contains the model's predictions, while the \"respuesta\" list contains the correct answers. Obviously, their lengths match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac80a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "qso_to_gal = []\n",
    "qso_to_star = []\n",
    "gal_to_star = []\n",
    "star_to_gal = []\n",
    "star_to_qso = []\n",
    "gal_to_qso = []\n",
    "\n",
    "for index, item in enumerate(y_pred_mlp):\n",
    "    if item == 'GALAXY' and y_validation[index] == 'QSO':\n",
    "        qso_to_gal.append(item)\n",
    "    elif item == 'STAR' and y_validation[index] == 'QSO':\n",
    "        qso_to_star.append(item)\n",
    "    elif item == 'GALAXY' and y_validation[index] == 'STAR':\n",
    "        star_to_gal.append(item)\n",
    "    elif item == 'STAR' and y_validation[index] == 'GALAXY':\n",
    "        gal_to_star.append(item)\n",
    "    elif item == 'QSO' and y_validation[index] == 'STAR':\n",
    "        star_to_qso.append(item)\n",
    "    elif item == 'QSO' and y_validation[index] == 'GALAXY':\n",
    "        gal_to_qso.append(item)\n",
    "\n",
    "print(len(qso_to_gal), \"qso to gal\")\n",
    "print(len(qso_to_star), \"qso to star\")\n",
    "print(len(gal_to_star), \"gal to star\")\n",
    "print(len(star_to_gal), \"star to gal\")\n",
    "print(len(star_to_qso), \"star to qso\")\n",
    "print(len(gal_to_qso), \"gal to qso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c000b-3667-4981-823b-323fa7eb9e51",
   "metadata": {
    "id": "355c000b-3667-4981-823b-323fa7eb9e51"
   },
   "outputs": [],
   "source": [
    "# Here we will calculate the metrics for purity, completeness, F1-score, confusion matrix, and MCC:\n",
    "\n",
    "\n",
    "# In case we only want to study the quasar case:\n",
    "# y_validation = quas_data_sgd\n",
    "# y_pred = y_pred_rf\n",
    "\n",
    "# Transform a vector with 3 different types of elements into a vector with 2 classes to use 'binary'.\n",
    "# Convert to binary: QSO or NOT QSO, with QSO as the positive class\n",
    "\n",
    "y_validation = ['QSO' if val == 'QSO' else 'NOT_QSO' for val in y_validation]\n",
    "y_pred = ['QSO' if val == 'QSO' else 'NOT_QSO' for val in y_pred_xn]\n",
    "\n",
    "\n",
    "####################################\n",
    "#y_pred=quas_predict_brf\n",
    "#y_validation=quas_data_brf\n",
    "\n",
    "#y_pred=y_pred_sgd\n",
    "\n",
    "\n",
    "# Precision:\n",
    "from sklearn.metrics import precision_score # Import the precision_score function from sklearn which directly calculates purity.\n",
    "# It computes the weighted average of all individual precisions according to the number of samples in each class. \n",
    "# If we want precision per class, we could use None instead of 'weighted'.\n",
    "\n",
    "purity = precision_score(y_validation, y_pred, average='binary', pos_label='QSO') # Compare the purity between the two lists we want.\n",
    "print(f\"Puresa (precisió): {purity:.4f}\") # Print the purity with 4 decimals.\n",
    "# Purity is the fraction of samples predicted positive as quasars among all samples predicted positive (including false positives).\n",
    "# Purity = True Positives / (True Positives + False Positives)\n",
    "\n",
    "\n",
    "\n",
    "# Recall:\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "completitud = recall_score(y_validation, y_pred, average='binary', pos_label='QSO') #average='binary', pos_label='QSO'\n",
    "print(f\"Completitud: {completitud:.4f}\")\n",
    "# Completeness is the proportion of samples of a class that our method correctly identifies, \n",
    "# i.e., the number of true positives divided by the sum of true positives and false negatives.\n",
    "# Completeness = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "\n",
    "\n",
    "# F1-score:\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_validation, y_pred, average='binary', pos_label='QSO') # Use average='macro' when we have 3 classes (y_pred and y_validation)\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "# The F1-score ranges from 0 to 1 and measures the balance between purity (precision), i.e., false positives, and completeness, which are false negatives. If F1=1, the classification is perfect.\n",
    "\n",
    "\n",
    "# Confussion matrix:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_validation, y_pred)\n",
    "print(\"Matriu de confusió:\")\n",
    "print(conf_matrix)\n",
    "# The confusion matrix allows us to easily visualize true positives, false positives, true negatives, and false negatives.\n",
    "\n",
    "\n",
    "# We will also calculate the MCC (Matthews Correlation Coefficient), which is a measure that indicates how well a classifier performs, \n",
    "# taking into account all possibilities of both correct predictions (true positives and true negatives) and errors (false positives and false negatives).\n",
    "# This metric is very good when we have a significant imbalance in the number of samples between classes, \n",
    "# whereas the F1 score can be misleading and would not perform as well.from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(y_validation, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "# With a random forest of 50 decision trees, we obtained the following results:\n",
    "# Precision: 0.9665;    Recall: 0.9669;    F1-score: 0.9646;    Confusion Matrix: [489464 1757 1646; 15860 24871 67; 5084 80 200591];    MCC: 0.929639494307183;\n",
    "# We can consider the results to be very good.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e73e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split: 300, leaf: 250\n",
    "'''\n",
    "y_pred_rf = clf.predict(X_validation)  # Dona la predicció de cada fila d'input, és a dir, de galàxia o quàsar o estrella. És un conjunt d'etiquetes de \"Galaxy\", \"Star\", \"QSO\"\n",
    "probs_pred = clf.predict_proba(X_validation)  # Dona les probabilitats de les prediccions per cada tipus.\n",
    "qso_index = list(clf.classes_).index(\"QSO\")  # Índex de la classe \"QSO\"\n",
    "\n",
    "# Extreu les probabilitats de ser QSO\n",
    "y_probs = probs_pred[:, qso_index]\n",
    "\n",
    "# Prediccions binàries: 1 si la probabilitat > 0.8, 0 si no\n",
    "y_pred = (y_probs > 0.8).astype(int)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#split: 300, leaf: 100\n",
    "'''\n",
    "Puresa (precisió): 0.4123\n",
    "Completitud: 0.8113\n",
    "F1-score: 0.5467\n",
    "Matriu de confusió:\n",
    "[[651024  47158]\n",
    " [  7697  33085]]\n",
    "Matthews Correlation Coefficient (MCC): 0.5458510722300596\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#split: 200, leaf: 50\n",
    "'''\"JPAS_DATA_Aper_Cor_3_FLUX+NOISE (1).npy\"Puresa (precisió): 0.4402\n",
    "Completitud: 0.8080\n",
    "F1-score: 0.5700\n",
    "Matriu de confusió:\n",
    "[[656284  41898]\n",
    " [  7829  32953]]\n",
    "Matthews Correlation Coefficient (MCC): 0.5661229836692495\n",
    "'''\n",
    "\n",
    "#split: 1000, leaf: 200\n",
    "'''\n",
    "Puresa (precisió): 0.3734\n",
    "Completitud: 0.8188\n",
    "F1-score: 0.5129\n",
    "Matriu de confusió:\n",
    "[[642156  56026]\n",
    " [  7391  33391]]\n",
    "Matthews Correlation Coefficient (MCC): 0.5170910203348833\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#None:\n",
    "'''\n",
    "Puresa (precisió): 0.7011\n",
    "Completitud: 0.5973\n",
    "F1-score: 0.6450\n",
    "Matriu de confusió:\n",
    "[[687795  10387]\n",
    " [ 16424  24358]]\n",
    "Matthews Correlation Coefficient (MCC): 0.6282565324524364\n",
    "'''\"JPAS_DATA_Aper_Cor_3_FLUX+NOISE (1).npy\"\n",
    "\n",
    "#40:No és millor que none\n",
    "#30: No és millor que none\n",
    "\n",
    "#50 arbres, class=None, depth=None, f1-score=0.67...\n",
    "\n",
    "#50 arbres, class='balanced', depth=None\n",
    "'''\"JPAS_DATA_Aper_Cor_3_FLUX+NOISE (1).npy\"Puresa (precisió): 0.7778\n",
    "Completitud: 0.6083\n",
    "F1-score: 0.6827\n",
    "Matriu de confusió:\n",
    "[[691096   7086]\n",
    " [ 15975  24807]]\n",
    "Matthews Correlation Coefficient (MCC): 0.6721059900351671\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcio_qso_scoring(sgdc, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a79cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred_rf_real\n",
    "\n",
    "#Primer de tot, per la PURESA:\n",
    "from sklearn.metrics import precision_score \n",
    "purity = precision_score(y_real, y_pred, average='weighted') \n",
    "print(f\"Puresa (precisió): {purity:.4f}\") \n",
    "\n",
    "\n",
    "#Per la COMPLETITUD:\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "completitud = recall_score(y_real, y_pred, average='weighted') \n",
    "print(f\"Completitud: {completitud:.4f}\")\n",
    "\n",
    "\n",
    "#Per la F1-score:\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_real, y_pred, average='weighted') \n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "#Per la MATRIU DE CONFUSIÓ:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_real, y_pred)\n",
    "print(\"Matriu de confusió:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "#També calculadrem la MCC (Matthews Correlation Coefficient), que és una mesura que indica com de bé funciona un classificador tenint en compte totes les possibilitats tant d'encerts (veritables positius i veritables negatuis) i errors (falsos positius i falsos negatius).\n",
    "#Aquesta mètrica és molt bona quan tenim nombres de mostres entre classes molt desequilibrades, mentre que la F1 es deixa enganyar i no funcionaria tan bé.\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(y_real, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
